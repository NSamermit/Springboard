{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>city</th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Austin</td>\n",
       "      <td>139</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>237</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mon</td>\n",
       "      <td>Austin</td>\n",
       "      <td>326</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mon</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>456</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekday    city  bread  butter\n",
       "0     Sun  Austin    139      20\n",
       "1     Sun  Dallas    237      45\n",
       "2     Mon  Austin    326      70\n",
       "3     Mon  Dallas    456      98"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Video 1 - Categoricals and groupby\n",
    "import pandas as pd\n",
    "sales = pd.DataFrame(\n",
    "        {\n",
    "        'weekday': ['Sun', 'Sun', 'Mon', 'Mon'],\n",
    "        'city': ['Austin', 'Dallas', 'Austin', 'Dallas'],\n",
    "        'bread': [139, 237, 326, 456],\n",
    "        'butter': [20, 45, 70, 98]\n",
    "        }\n",
    ")\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekday    2\n",
       "city       2\n",
       "bread      2\n",
       "butter     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#could use boolean filtering to find all sales made on Sunday and count them\n",
    "sales.loc[sales['weekday'] == 'Sun'].count()\n",
    "#requires for us to know the disticnt entries of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mon</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sun</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  bread  butter\n",
       "weekday                     \n",
       "Mon         2      2       2\n",
       "Sun         2      2       2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternatively we can groupby the weekday column and count entries for each distict value found\n",
    "sales.groupby('weekday').count()\n",
    "#more convenient - don't need to know the distinct entires of the columns\n",
    "df.groupby('IndexGroupedByThisCol')['subselectThisCol'].aggregationMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A closer look:\n",
    "sales.groupby('weekday').count()\n",
    "1. split by weekday\n",
    "2. apply count() function to each group of rows\n",
    "3. combine results in a new DF with distinct values of weekday in the index\n",
    "\n",
    "Count method is an aggregation or reduction because it reduces many values into a single value\n",
    "Aggregation/ Reduction in groupy:\n",
    "1. mean()\n",
    "2. std()\n",
    "3. sum()\n",
    "4. first(), last()\n",
    "5. max(), min()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekday\n",
       "Mon    782\n",
       "Sun    376\n",
       "Name: bread, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Groupby and sum\n",
    "sales.groupby('weekday')['bread'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mon</td>\n",
       "      <td>782</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sun</td>\n",
       "      <td>376</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bread  butter\n",
       "weekday               \n",
       "Mon        782     168\n",
       "Sun        376      65"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Groupby and sum: multiple columns\n",
    "#can use a list of columns\n",
    "sales.groupby('weekday')[['bread', 'butter']].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>weekday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">Austin</td>\n",
       "      <td>Mon</td>\n",
       "      <td>326</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sun</td>\n",
       "      <td>139</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">Dallas</td>\n",
       "      <td>Mon</td>\n",
       "      <td>456</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sun</td>\n",
       "      <td>237</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bread  butter\n",
       "city   weekday               \n",
       "Austin Mon        326      70\n",
       "       Sun        139      20\n",
       "Dallas Mon        456      98\n",
       "       Sun        237      45"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can groupby multilevel by passing in  multiple column names in a list\n",
    "sales.groupby(['city', 'weekday']).mean()\n",
    "#the result is the avg amnt of bread and butter bought at each of the two locations on Sun and Mon\n",
    "#this returns a SORTED multi-level index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Dave\n",
       "1    Alice\n",
       "2      Bob\n",
       "3    Alice\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Groupby can use any Pandas Series with the same index values\n",
    "customers = pd.Series(['Dave', 'Alice', 'Bob', 'Alice'])\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice    693\n",
       "Bob      326\n",
       "Dave     139\n",
       "Name: bread, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby and sum: by Series\n",
    "#customers df has an identical index to sales df\n",
    "#df.groupby(SerieswithSameIndex)[subselectColumn].aggFunc()\n",
    "sales.groupby(customers)['bread'].sum()\n",
    "#results in a new Series with a customer name in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sun', 'Mon'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorical Data\n",
    "#using .unique() on a Series returns an array of the distinct entries\n",
    "sales['weekday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sun    2\n",
       "Mon    2\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find out how many times each individual value occurs in that Series use .value_counts()\n",
    "sales['weekday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Sun\n",
       "1    Sun\n",
       "2    Mon\n",
       "3    Mon\n",
       "Name: weekday, dtype: category\n",
       "Categories (2, object): [Mon, Sun]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform weekday column into a categorical type\n",
    "sales['weekday'] = sales['weekday'].astype('category')\n",
    "sales['weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What are the advantages of categoricals over strings?\n",
    "    1. Uses less memory\n",
    "    2. speeds up operations like groupby()\n",
    "\n",
    "Series entries are stored using small integers and a seperate look-up table\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass\n",
      "1    323\n",
      "2    277\n",
      "3    709\n",
      "Name: survived, dtype: int64\n",
      "embarked  pclass\n",
      "C         1         141\n",
      "          2          28\n",
      "          3         101\n",
      "Q         1           3\n",
      "          2           7\n",
      "          3         113\n",
      "S         1         177\n",
      "          2         242\n",
      "          3         495\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Ex1 - grouping by multiple columns\n",
    "csv = \"titanic.csv\"\n",
    "titanic = pd.read_csv(csv)\n",
    "titanic.head()\n",
    "\n",
    "# Group titanic by 'pclass'\n",
    "by_class = titanic.groupby('pclass') #this is a df generator object\n",
    "\n",
    "# Aggregate 'survived' column of by_class by count\n",
    "count_by_class = by_class['survived'].count()\n",
    "\n",
    "# Print count_by_class\n",
    "print(count_by_class)\n",
    "\n",
    "# Group titanic by 'embarked' and 'pclass'\n",
    "by_mult = titanic.groupby(['embarked', 'pclass'])\n",
    "\n",
    "# Aggregate 'survived' column of by_mult by count\n",
    "count_mult = by_mult['survived'].count()\n",
    "\n",
    "# Print count_mult\n",
    "print(count_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url1 = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1650/datasets/life_expectancy.csv' #has to be a string\n",
    "r = requests.get(url1)\n",
    "\n",
    "with open('life_fname.csv', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "life_fname = 'life_fname.csv'\n",
    "\n",
    "url2 = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1650/datasets/regions.csv'\n",
    "r2 = requests.get(url2)\n",
    "with open('regions_fname.csv', 'wb') as f:\n",
    "    f.write(r2.content)\n",
    "regions_fname = 'regions_fname.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region\n",
      "America                       74.037350\n",
      "East Asia & Pacific           73.405750\n",
      "Europe & Central Asia         75.656387\n",
      "Middle East & North Africa    72.805333\n",
      "South Asia                    68.189750\n",
      "Sub-Saharan Africa            57.575080\n",
      "Name: 2010, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ex2 = Groupying by another series\n",
    "\n",
    "\n",
    "# Read life_fname into a DataFrame: life\n",
    "life = pd.read_csv(life_fname, index_col='Country')\n",
    "\n",
    "# Read regions_fname into a DataFrame: regions\n",
    "regions = pd.read_csv(regions_fname, index_col='Country')\n",
    "#print(type(regions))\n",
    "\n",
    "# Group life by regions['region']: life_by_region\n",
    "life_by_region = life.groupby(regions['region']) #regions is a df, not a Series\n",
    "#that's why use regions['region'] rather than .groupby(regions)['region']\n",
    "\n",
    "# Print the mean over the '2010' column of life_by_region\n",
    "print(life_by_region['2010'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Austin</td>\n",
       "      <td>326</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dallas</td>\n",
       "      <td>456</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bread  butter\n",
       "city                 \n",
       "Austin    326      70\n",
       "Dallas    456      98"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Video 2- Groupby and aggregation\n",
    "sales\n",
    "#Review: groupby\n",
    "#groupby a column, select one or more columns on which to perform aggregation:\n",
    "sales.groupby('city')[['bread', 'butter']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">bread</th>\n",
       "      <th colspan=\"3\" halign=\"left\">butter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Austin</td>\n",
       "      <td>326</td>\n",
       "      <td>139</td>\n",
       "      <td>465</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dallas</td>\n",
       "      <td>456</td>\n",
       "      <td>237</td>\n",
       "      <td>693</td>\n",
       "      <td>98</td>\n",
       "      <td>45</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bread           butter         \n",
       "         max  min  sum    max min  sum\n",
       "city                                  \n",
       "Austin   326  139  465     70  20   90\n",
       "Dallas   456  237  693     98  45  143"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiple aggregations\n",
    "#using .agg() we can do several\n",
    "sales.groupby('city')[['bread', 'butter']].agg(['max', 'min', 'sum'])\n",
    "#three aggregations are computed for each column (bread and butter) for each group (Austin, Dallas)\n",
    "#the result is a MultiLevel index for the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mon</td>\n",
       "      <td>130</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sun</td>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bread  butter\n",
       "weekday               \n",
       "Mon        130      28\n",
       "Sun         98      25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregation functions\n",
    "#can be used in many different ways:\n",
    "#1. pass a list of strings repr common agg methods: sum, mean, count\n",
    "#2. accepts user-defined functions or library functions\n",
    "#3. Accepts a dict as input\n",
    "\n",
    "def data_range(series):\n",
    "    return series.max() - series.min()\n",
    "#data_range IS an aggregation because it RECEIVES a series and RETURNS a single number\n",
    "\n",
    "sales.groupby('weekday')[['bread', 'butter']].agg(data_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Alice</td>\n",
       "      <td>693</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bob</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dave</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bread  butter\n",
       "Alice    693      53\n",
       "Bob      326       0\n",
       "Dave     139       0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.groupby(customers)[['bread', 'butter']].agg({'bread':'sum', 'butter':data_range})\n",
    "#dict keys are column names\n",
    "#dict vals are agg funcs to apply to EACH column\n",
    "#note because data_range is a user-defined function - no need for ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max age in each class\n",
      " pclass\n",
      "1    80.0\n",
      "2    70.0\n",
      "3    74.0\n",
      "Name: (age, max), dtype: float64\n",
      "Median fare in each class\n",
      " pclass\n",
      "1    60.0000\n",
      "2    15.0458\n",
      "3     8.0500\n",
      "Name: (fare, median), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ex3 - Computing multiple aggregates of multiple columns\n",
    "#Reminder: When applying multiple aggregations on multiple columns, the aggregated DataFrame has a \n",
    "# multi-level column index.\n",
    "\n",
    "# Group titanic by 'pclass': by_class\n",
    "by_class = titanic.groupby('pclass')\n",
    "\n",
    "# Select 'age' and 'fare'\n",
    "by_class_sub = by_class[['age','fare']]\n",
    "\n",
    "# Aggregate by_class_sub by 'max' and 'median': aggregated\n",
    "aggregated = by_class_sub.agg(['max', 'median'])\n",
    "\n",
    "# Print the maximum age in each class\n",
    "print('Max age in each class\\n', aggregated.loc[:, ('age','max')]) #interesting, [all rows, (from age column, choose max value)]\n",
    "\n",
    "# Print the median fare in each class\n",
    "print('Median fare in each class\\n', aggregated.loc[:, ('fare', 'median')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                         fertility    life  population  \\\n",
       "Year region                Country                                      \n",
       "1964 South Asia            Afghanistan      7.671  33.639  10474903.0   \n",
       "1965 South Asia            Afghanistan      7.671  34.152  10697983.0   \n",
       "1966 South Asia            Afghanistan      7.671  34.662  10927724.0   \n",
       "1967 South Asia            Afghanistan      7.671  35.170  11163656.0   \n",
       "1968 South Asia            Afghanistan      7.671  35.674  11411022.0   \n",
       "...                                           ...     ...         ...   \n",
       "2002 Europe & Central Asia Åland              NaN  81.800     26257.0   \n",
       "2003 Europe & Central Asia Åland              NaN  80.630     26347.0   \n",
       "2004 Europe & Central Asia Åland              NaN  79.880     26530.0   \n",
       "2005 Europe & Central Asia Åland              NaN  80.000     26766.0   \n",
       "2006 Europe & Central Asia Åland              NaN  80.100     26923.0   \n",
       "\n",
       "                                        child_mortality     gdp  \n",
       "Year region                Country                               \n",
       "1964 South Asia            Afghanistan            339.7  1182.0  \n",
       "1965 South Asia            Afghanistan            334.1  1182.0  \n",
       "1966 South Asia            Afghanistan            328.7  1168.0  \n",
       "1967 South Asia            Afghanistan            323.3  1173.0  \n",
       "1968 South Asia            Afghanistan            318.1  1187.0  \n",
       "...                                                 ...     ...  \n",
       "2002 Europe & Central Asia Åland                    NaN     NaN  \n",
       "2003 Europe & Central Asia Åland                    NaN     NaN  \n",
       "2004 Europe & Central Asia Åland                    NaN     NaN  \n",
       "2005 Europe & Central Asia Åland                    NaN     NaN  \n",
       "2006 Europe & Central Asia Åland                    NaN     NaN  \n",
       "\n",
       "[10111 rows x 5 columns]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'gapminder_tidy.csv'\n",
    "gapminder = pd.read_csv(csv, index_col=['Year', 'region', 'Country'])\n",
    "gapminder.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   population  child_mortality       gdp\n",
      "Year region                                                             \n",
      "2013 America                     9.629087e+08        17.745833   49634.0\n",
      "     East Asia & Pacific         2.244209e+09        22.285714  134744.0\n",
      "     Europe & Central Asia       8.968788e+08         9.831875   86418.0\n",
      "     Middle East & North Africa  4.030504e+08        20.221500  128676.0\n",
      "     South Asia                  1.701241e+09        46.287500   11469.0\n",
      "     Sub-Saharan Africa          9.205996e+08        76.944490   32035.0\n"
     ]
    }
   ],
   "source": [
    "#Ex4 - Aggregating on index levels/fields\n",
    "#in a multi-level row indexed DF, individual levels can be use dto perform groupby\n",
    "#this allows ADVANCED aggregation techniques to be applied along one or more levels in the index\n",
    "# accross one or more columns\n",
    "#uses gapminder_tidy.csv which was imported above\n",
    "\n",
    "# Read the CSV file into a DataFrame and sort the index: gapminder\n",
    "gapminder = pd.read_csv(csv, index_col=['Year', 'region', 'Country'])\n",
    "gapminder.sort_index(inplace=True)\n",
    "\n",
    "# Group gapminder by 'Year' and 'region': by_year_region\n",
    "by_year_region = gapminder.groupby(level=['Year', 'region']) #level is usually an int. Can I use a list of strings?\n",
    "#yes, level will take list\n",
    "# Define the function to compute spread: spread\n",
    "def spread(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "# Create the dictionary: aggregator\n",
    "aggregator = {'population':'sum', 'child_mortality':'mean', 'gdp':spread} #spread is a user-defined func\n",
    "\n",
    "# Aggregate by_year_region using the dictionary: aggregated\n",
    "aggregated = by_year_region.agg(aggregator)\n",
    "\n",
    "# Print the last 6 entries of aggregated \n",
    "print(aggregated.tail(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon    48\n",
      "Sat     7\n",
      "Thu    59\n",
      "Tue    13\n",
      "Wed    48\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Ex5 - Grouping on a function of the index\n",
    "#groupby can alost be performed on transformation of the index values\n",
    "#incase of a DateTimeIndex, we can extract portions of the datetime over which to group\n",
    "\n",
    "\n",
    "# Read file: sales\n",
    "sales = pd.read_csv('sales-feb-2015.csv', index_col ='Date', parse_dates=True)\n",
    "#csv name different than DataCamp submission\n",
    "\n",
    "# Create a groupby object: by_day\n",
    "by_day = sales.groupby(sales.index.strftime('%a')) \n",
    "#print(by_day, '\\n', type(by_day))\n",
    "# Create sum: units_sum\n",
    "units_sum = by_day['Units'].sum()\n",
    "\n",
    "# Print units_sum\n",
    "print(units_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video 3 - Groupby and transformations\n",
    "#Often want to group data, and apply distinct transformations to distinct groups\n",
    "#instead of aggregating AFTER grouping, we can apply transform method instead\n",
    "#Changes DF entries to a spec'd func w/o changing the index\n",
    "\n",
    "def zscore(series):\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "zscore(df['column']).head() #can apply to a df column\n",
    "\n",
    "#alternative: can normalize column data by index rather than over whole population\n",
    "df.groupby('index item')['column'].transform(func).head()\n",
    "\n",
    "#We know:\n",
    "    #1. .agg() applies reduction\n",
    "    #2. .transform() applies a func elt wise to groups\n",
    "    \n",
    "    #In some cases, split-apply-combine operations do not neatly fall into agg or transformations\n",
    "    #in those cases, we use apply\n",
    "    \n",
    "def zscore_with_year_and_name(group):\n",
    "    df = pd.DataFrame(\n",
    "         {\n",
    "             'mpg':zscore(group['mpg']), #transform mpg column\n",
    "             'year':group['yr'], #take original values from yr column\n",
    "             'name':group['name'] #take original values from name column\n",
    "         }\n",
    "    )\n",
    "    return df\n",
    "\n",
    "#this function is too complicate for .transform(), so we use .apply() instead\n",
    "auto.groupby('yr').apply(zscore_with_year_and_name).head()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gapminder index: \n",
      " MultiIndex([(1964,            'America', 'Antigua and Barbuda'),\n",
      "            (1964,            'America',           'Argentina'),\n",
      "            (1964,            'America',               'Aruba'),\n",
      "            (1964,            'America',             'Bahamas'),\n",
      "            (1964,            'America',            'Barbados'),\n",
      "            (1964,            'America',              'Belize'),\n",
      "            (1964,            'America',             'Bolivia'),\n",
      "            (1964,            'America',              'Brazil'),\n",
      "            (1964,            'America',              'Canada'),\n",
      "            (1964,            'America',               'Chile'),\n",
      "            ...\n",
      "            (2013, 'Sub-Saharan Africa',             'Somalia'),\n",
      "            (2013, 'Sub-Saharan Africa',        'South Africa'),\n",
      "            (2013, 'Sub-Saharan Africa',         'South Sudan'),\n",
      "            (2013, 'Sub-Saharan Africa',               'Sudan'),\n",
      "            (2013, 'Sub-Saharan Africa',           'Swaziland'),\n",
      "            (2013, 'Sub-Saharan Africa',            'Tanzania'),\n",
      "            (2013, 'Sub-Saharan Africa',                'Togo'),\n",
      "            (2013, 'Sub-Saharan Africa',              'Uganda'),\n",
      "            (2013, 'Sub-Saharan Africa',              'Zambia'),\n",
      "            (2013, 'Sub-Saharan Africa',            'Zimbabwe')],\n",
      "           names=['Year', 'region', 'Country'], length=10111)\n",
      "g2 index: \n",
      " RangeIndex(start=0, stop=10111, step=1)\n"
     ]
    }
   ],
   "source": [
    "#had gapminder already, but there were three elts in index - had to reset index\n",
    "gapminder.describe\n",
    "gapminder.index\n",
    "print('Gapminder index: \\n', gapminder.index)\n",
    "try:\n",
    "    g2 = gapminder.reset_index()\n",
    "except ValurError as e:\n",
    "    print(e)\n",
    "\n",
    "print('g2 index: \\n', g2.index)\n",
    "#g2 no longer has a multiIndex of Year, Country, and region. It's all reset as a Range(0, 10111, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Afghanistan', 'Albania', 'Algeria', 'Angola', 'Antigua and Barbuda',\n",
       "       'Argentina', 'Armenia', 'Aruba', 'Australia', 'Austria',\n",
       "       ...\n",
       "       'Uzbekistan', 'Vanuatu', 'Venezuela', 'Vietnam',\n",
       "       'Virgin Islands (U.S.)', 'West Bank and Gaza', 'Western Sahara',\n",
       "       'Yemen, Rep.', 'Zambia', 'Zimbabwe'],\n",
       "      dtype='object', name='Country', length=202)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set index to only \"Year\" and \"Country\"\n",
    "test = g2.set_index(['Year', 'Country'])\n",
    "\n",
    "#sliced it by the year 2010, and all countries then sorted \n",
    "gapminder_2010 = test.loc[2010,:].sort_index()\n",
    "gapminder_2010.describe\n",
    "gapminder_2010.columns\n",
    "gapminder_2010.index\n",
    "#ok this seems to match DataCamp now, continue with Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            region  fertility    life  population  \\\n",
      "Country                                                             \n",
      "Guatemala                  America      3.974  71.100  14388929.0   \n",
      "Haiti                      America      3.350  45.000   9993247.0   \n",
      "Tajikistan   Europe & Central Asia      3.780  66.830   6878637.0   \n",
      "Timor-Leste    East Asia & Pacific      6.237  65.952   1124355.0   \n",
      "\n",
      "             child_mortality     gdp  \n",
      "Country                               \n",
      "Guatemala               34.5  6849.0  \n",
      "Haiti                  208.8  1518.0  \n",
      "Tajikistan              52.6  2110.0  \n",
      "Timor-Leste             63.8  1777.0  \n"
     ]
    }
   ],
   "source": [
    "#Ex6\n",
    "#can apply a .transform() after grouping to apply a function to groups of data independently\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Group gapminder_2010: standardized\n",
    "standardized = gapminder_2010.groupby('region')[['life', 'fertility']].transform(zscore) \n",
    "\n",
    "#method groupby is not subscriptable\n",
    "#use () when calling 'region' column not [] because we aren't calling an index\n",
    "#i forgot the semantics here\n",
    "#df.groupby(groupIndexByThis'column name')[[select these and do]].transform(using this func)\n",
    "\n",
    "\n",
    "# Construct a Boolean Series to identify outliers: outliers\n",
    "outliers = (standardized['life'] < -3) | (standardized['fertility'] > 3)\n",
    "\n",
    "# Filter gapminder_2010 by the outliers: gm_outliers\n",
    "gm_outliers = gapminder_2010.loc[outliers]\n",
    "\n",
    "# Print gm_outliers\n",
    "print(gm_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29.00\n",
       "1     0.92\n",
       "2     2.00\n",
       "3    30.00\n",
       "4    25.00\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('titanic.csv') #had to reread the file for this assignment - the ages weren't correct\n",
    "titanic.age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pclass  survived                                     name     sex   age  \\\n",
      "1299       3         0                      Yasbeck, Mr. Antoni    male  27.0   \n",
      "1300       3         1  Yasbeck, Mrs. Antoni (Selini Alexander)  female  15.0   \n",
      "1301       3         0                     Youseff, Mr. Gerious    male  45.5   \n",
      "1302       3         0                        Yousif, Mr. Wazli    male  25.0   \n",
      "1303       3         0                    Yousseff, Mr. Gerious    male  25.0   \n",
      "1304       3         0                     Zabour, Miss. Hileni  female  14.5   \n",
      "1305       3         0                    Zabour, Miss. Thamine  female  22.0   \n",
      "1306       3         0                Zakarian, Mr. Mapriededer    male  26.5   \n",
      "1307       3         0                      Zakarian, Mr. Ortin    male  27.0   \n",
      "1308       3         0                       Zimmerman, Mr. Leo    male  29.0   \n",
      "\n",
      "      sibsp  parch  ticket     fare cabin embarked boat   body home.dest  \n",
      "1299      1      0    2659  14.4542   NaN        C    C    NaN       NaN  \n",
      "1300      1      0    2659  14.4542   NaN        C  NaN    NaN       NaN  \n",
      "1301      0      0    2628   7.2250   NaN        C  NaN  312.0       NaN  \n",
      "1302      0      0    2647   7.2250   NaN        C  NaN    NaN       NaN  \n",
      "1303      0      0    2627  14.4583   NaN        C  NaN    NaN       NaN  \n",
      "1304      1      0    2665  14.4542   NaN        C  NaN  328.0       NaN  \n",
      "1305      1      0    2665  14.4542   NaN        C  NaN    NaN       NaN  \n",
      "1306      0      0    2656   7.2250   NaN        C  NaN  304.0       NaN  \n",
      "1307      0      0    2670   7.2250   NaN        C  NaN    NaN       NaN  \n",
      "1308      0      0  315082   7.8750   NaN        S  NaN    NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "#Ex7 - Filling missing data (imputation) by group\n",
    "#ML and stats packages cannot determine best action when missing data entries are encountered\n",
    "#instead of using .drop_na(), can fill missing data with .groupby() and .transform()\n",
    "\n",
    "# Create a groupby object: by_sex_class\n",
    "by_sex_class = titanic.groupby(['sex', 'pclass'])\n",
    "\n",
    "# Write a function that imputes median\n",
    "def impute_median(series):\n",
    "    return series.fillna(series.median())\n",
    "#this func fills NaN values with median\n",
    "\n",
    "# Impute age and assign to titanic['age']\n",
    "#titanic.age = by_sex_class.age.transform(impute_median) #age is a Series, can be chained or called in []\n",
    "#age is fed into .transform(inpute_median(age)) but not literally...\n",
    "#semantics: df.argGoingIntoFunc.transform(func)\n",
    "titanic.age = by_sex_class['age'].transform(impute_median)\n",
    "\n",
    "# Print the output of titanic.tail(10)\n",
    "print(titanic.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex   pclass      \n",
      "male  3       1296    27.0\n",
      "              1297    25.0\n",
      "              1298    36.0\n",
      "              1299    27.0\n",
      "              1301    45.5\n",
      "              1302    25.0\n",
      "              1303    25.0\n",
      "              1306    26.5\n",
      "              1307    27.0\n",
      "              1308    29.0\n",
      "Name: age, dtype: float64\n",
      "sex   pclass      \n",
      "male  3       1296    male\n",
      "              1297    male\n",
      "              1298    male\n",
      "              1299    male\n",
      "              1301    male\n",
      "              1302    male\n",
      "              1303    male\n",
      "              1306    male\n",
      "              1307    male\n",
      "              1308    male\n",
      "Name: sex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test = by_sex_class.apply(impute_median) #this doesn't work because apply worked on the groups\n",
    "#sex and class, not age\n",
    "print(test.age.tail(10)) #note how the age medians are different than above\n",
    "print(test.sex.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  z(gdp)  regional spread(gdp)\n",
      "Country                                       \n",
      "United States   3.013374               47855.0\n",
      "United Kingdom  0.572873               89037.0\n",
      "China          -0.432756               96993.0\n"
     ]
    }
   ],
   "source": [
    "#Ex8 - Other transformations with .apply()\n",
    "#The .apply() method when used on a groupby object performs an arbitrary function on each of the \n",
    "#groups. These functions can be aggregations, transformations or more complex workflows. \n",
    "#The .apply() method will then combine the results in an intelligent way.\n",
    "\n",
    "def disparity(gr):\n",
    "    # Compute the spread of gr['gdp']: s\n",
    "    s = gr['gdp'].max() - gr['gdp'].min()\n",
    "    # Compute the z-score of gr['gdp'] as (gr['gdp']-gr['gdp'].mean())/gr['gdp'].std(): z\n",
    "    z = (gr['gdp'] - gr['gdp'].mean())/gr['gdp'].std()\n",
    "    # Return a DataFrame with the inputs {'z(gdp)':z, 'regional spread(gdp)':s}\n",
    "    return pd.DataFrame({'z(gdp)':z , 'regional spread(gdp)':s})\n",
    "\n",
    "# Group gapminder_2010 by 'region': regional\n",
    "regional = gapminder_2010.groupby('region')\n",
    "\n",
    "# Apply the disparity function on regional: reg_disp\n",
    "reg_disp = regional.apply(disparity)\n",
    "\n",
    "# Print the disparity of 'United States', 'United Kingdom', and 'China'\n",
    "print(reg_disp.loc[['United States', 'United Kingdom', 'China']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video 4 - Groupby and filtering\n",
    "\n",
    "#What if we want to  filter a groupby?\n",
    "#first start with splitting before aggregating\n",
    "\n",
    "#groupby objects\n",
    "#save the output of groupby as \"splitting\" before aggregating\n",
    "splitting = auto.groupby('yr')\n",
    "type(splitting) would return pandas.core.groupby.DataFrameGroupBy\n",
    "#splitting has an attribute .groups which is a dictionary\n",
    "type(splitting.groups) would return dict\n",
    "splitting.groups keys are the 'yrs' and values are the corresponding rows of the original DF\n",
    "\n",
    "#can ITERATE and carry out computations using loops\n",
    "for k,v in splitting:\n",
    "    do something with k,v\n",
    "    \n",
    "#can rewrite the loop as a dict comprehension\n",
    "chevy_means = {year:group.loc[group['name'].str.contains('chevrolet'), 'mpg'].mean() for year,group in splitting}\n",
    "#in chevy_means the keys are the years and the values are the filtered mpg averages for Chevrolet\n",
    "\n",
    "#can construct a panda Series with chevy_means dict\n",
    "pd.Series(chevy_means)\n",
    "\n",
    "#Boolean groupby - can use a boolean Series with same index in .groupby\n",
    "#to perform a one-to-all comparison\n",
    "chevy = auto['name'].str.contains('chevrolet')\n",
    "type(chevy) should return Boolean Series\n",
    "auto.groupby(['yr', chevy])['mpg'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n",
       "       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reload titanic\n",
    "titanic =  pd.read_csv('titanic.csv')\n",
    "titanic.index\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "female    0.913043\n",
      "male      0.312500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ex9\n",
    "#by using .apply() you can write functions that filter rows within groups. the .apply() method\n",
    "# will handle the iteration over individual groups and then re-combine them back into a Series or DF\n",
    "\n",
    "#Goal: analyze survival rates from the 'C' deck\n",
    "\n",
    "#provided function:\n",
    "def c_deck_survival(gr):\n",
    "\n",
    "    c_passengers = gr['cabin'].str.startswith('C').fillna(False) #filter for \"C\" cabin\n",
    "\n",
    "    return gr.loc[c_passengers, 'survived'].mean()\n",
    "\n",
    "# Create a groupby object using titanic over the 'sex' column: by_sex\n",
    "by_sex = titanic.groupby('sex')\n",
    "\n",
    "# Call by_sex.apply with the function c_deck_survival\n",
    "c_surv_by_sex = by_sex.apply(c_deck_survival)\n",
    "\n",
    "# Print the survival rates\n",
    "print(c_surv_by_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'Product', 'Units'], dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reload sales_2015.csv for Ex10\n",
    "sales = pd.read_csv('sales-feb-2015.csv', index_col = 'Date', parse_dates=True)\n",
    "sales.describe\n",
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company\n",
      "Acme Coporation    34\n",
      "Hooli              30\n",
      "Initech            30\n",
      "Mediacore          45\n",
      "Streeplex          36\n",
      "Name: Units, dtype: int64\n",
      "                       Company   Product  Units\n",
      "Date                                           \n",
      "2015-02-02 21:00:00  Mediacore  Hardware      9\n",
      "2015-02-04 15:30:00  Streeplex  Software     13\n",
      "2015-02-09 09:00:00  Streeplex   Service     19\n",
      "2015-02-09 13:00:00  Mediacore  Software      7\n",
      "2015-02-19 11:00:00  Mediacore  Hardware     16\n",
      "2015-02-19 16:00:00  Mediacore   Service     10\n",
      "2015-02-21 05:00:00  Mediacore  Software      3\n",
      "2015-02-26 09:00:00  Streeplex   Service      4\n"
     ]
    }
   ],
   "source": [
    "#Ex10 - Grouping and filtering with .filter()\n",
    "#Can use groupby with the .filter() method to remove whole groups of rows from a DF based\n",
    "#on a boolean condition\n",
    "\n",
    "#Goal: take February sales data and remove entries from companies that purchased less than or equal\n",
    "# to 35 units in the whole month\n",
    "\n",
    "# Read the CSV file into a DataFrame: sales\n",
    "#sales = pd.read_csv('sales.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Group sales by 'Company': by_company\n",
    "by_company = sales.groupby('Company')\n",
    "\n",
    "# Compute the sum of the 'Units' of by_company: by_com_sum\n",
    "by_com_sum = by_company['Units'].apply(sum)\n",
    "print(by_com_sum)\n",
    "\n",
    "# Filter 'Units' where the sum is > 35: by_com_filt\n",
    "by_com_filt = by_company.filter(lambda g: g['Units'].sum() > 35)\n",
    "print(by_com_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "over 10     0.366748\n",
      "under 10    0.609756\n",
      "Name: survived, dtype: float64\n",
      "age       pclass\n",
      "over 10   1         0.617555\n",
      "          2         0.380392\n",
      "          3         0.238897\n",
      "under 10  1         0.750000\n",
      "          2         1.000000\n",
      "          3         0.446429\n",
      "Name: survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ex11 - Filtering and grouping with .map()\n",
    "#Sometimes you want to group by a function/transformation of a column\n",
    "#the key is the Series is indexed the same as the DF. \n",
    "#Can also mix match column grouping with Series grouping\n",
    "\n",
    "#Goal: investigate survival rates of passengers by 'age' and 'pclass'\n",
    "    #Find out what fraction of children under 10 srurived in each 'pclass'\n",
    "    \n",
    "#titanic.describe\n",
    "#titanic.columns\n",
    "#len(titanic.columns) \n",
    "#confirmed my titanic matches with DataCamp's\n",
    "\n",
    "# Create the Boolean Series: under10\n",
    "under10 = titanic['age'] < 10\n",
    "under10 = under10.map({True:'under 10', False:'over 10'})\n",
    "\n",
    "# Group by under10 and compute the survival rate\n",
    "survived_mean_1 = titanic.groupby(under10).survived.mean()\n",
    "print(survived_mean_1)\n",
    "\n",
    "# Group by under10 and pclass and compute the survival rate\n",
    "survived_mean_2 = titanic.groupby([under10, 'pclass']).survived.mean()\n",
    "#under10 is a Boolean Series, does not need ''\n",
    "print(survived_mean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
